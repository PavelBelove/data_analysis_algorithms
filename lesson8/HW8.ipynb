{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn import datasets\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier as RFC\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(150, 4)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Загрузим игрушечный датасет из sklearn\n",
    "iris = datasets.load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Обучить любую модель классификации на датасете iris до применения PCA и после него. Сравнить качество классификации по отложенной выборке."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(150, 2)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_pca = PCA(n_components=2, random_state=42).fit_transform(X)\n",
    "X_pca.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_pca, X_test_pca, y_train_pca, y_test_pca = train_test_split(X_pca, y, test_size=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = RFC(n_jobs=-1).fit(X_train, y_train)\n",
    "clf_pca = RFC(n_jobs=-1).fit(X_train_pca, y_train_pca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "До применения PCA F1-score: 0.9736842105263158\n",
      "После применения PCA F1-score: 0.9736842105263158\n"
     ]
    }
   ],
   "source": [
    "print(f\"До применения PCA F1-score: {f1_score(y_test, clf.predict(X_test), average='micro')}\")\n",
    "print(f\"После применения PCA F1-score: {f1_score(y_test_pca, clf_pca.predict(X_test_pca), average='micro')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Написать свою реализацию метода главных компонент с помощью сингулярного разложения с использованием функции numpy.linalg.svd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "means = X.mean(axis=0)\n",
    "stds = X.std(axis=0, ddof=1)\n",
    "\n",
    "X_scaled = (X - means)/stds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fro_norm(X):\n",
    "    return np.sum(X ** 2) ** 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pca_with_svd(X, n_components):\n",
    "    U, s, Vt = np.linalg.svd(X)\n",
    "    \n",
    "    D = np.zeros_like(X, dtype=float)\n",
    "    D[np.diag_indices(min(X.shape))] = s\n",
    "    V = Vt.T\n",
    "    \n",
    "    # проверка\n",
    "    np.testing.assert_array_almost_equal(U.dot(D).dot(Vt), X)\n",
    "    \n",
    "    W = V[:, :n_components]\n",
    "    Z = X.dot(W)\n",
    "    \n",
    "    return Z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_pca_4 = pca_with_svd(X_scaled, n_components=4)\n",
    "X_pca_3 = pca_with_svd(X_scaled, n_components=3)\n",
    "X_pca_2 = pca_with_svd(X_scaled, n_components=2)\n",
    "X_pca_1 = pca_with_svd(X_scaled, n_components=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Норма Фробениуса:\n",
      " - исходной матрицы X:   24.413111231467408\n",
      " - четырех ГК матрицы X: 24.41311123146741\n",
      " - трех ГК матрицы X:    24.34981497613762\n",
      " - двух ГК матрицы X:    23.896583749816834\n",
      " - одной ГК матрицы X:   20.853205381026378\n"
     ]
    }
   ],
   "source": [
    "print('Норма Фробениуса:')\n",
    "print(f' - исходной матрицы X:   {fro_norm(X_scaled)}')\n",
    "print(f' - четырех ГК матрицы X: {fro_norm(X_pca_4)}')\n",
    "print(f' - трех ГК матрицы X:    {fro_norm(X_pca_3)}')\n",
    "print(f' - двух ГК матрицы X:    {fro_norm(X_pca_2)}')\n",
    "print(f' - одной ГК матрицы X:   {fro_norm(X_pca_1)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Норма Фробениуса существенно изменяется с понижением количества главных компонент."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Курсовая работа в папке course_work\n",
    "\n",
    "Еще раз огрромное спасибо за курс)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
