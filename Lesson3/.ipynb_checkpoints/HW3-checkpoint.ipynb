{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jVKnqZEmWjr0"
   },
   "source": [
    "# Урок 3. Классификация. Логистическая регрессия."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Домашнее задание <a class='anchor' id='hw'>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array([ [   1,    1,  500,    1],\n",
    "               [   1,    1,  700,    1],\n",
    "               [   1,    2,  750,    2],\n",
    "               [   1,    5,  600,    1],\n",
    "               [   1,    3, 1450,    2],\n",
    "               [   1,    0,  800,    1],\n",
    "               [   1,    5, 1500,    3],\n",
    "               [   1,   10, 2000,    3],\n",
    "               [   1,    1,  450,    1],\n",
    "               [   1,    2, 1000,    2]], dtype = np.float64)\n",
    "\n",
    "y = np.array([0, 0, 1, 0, 1, 0, 1, 0, 1, 1], dtype = np.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def standard_scale(x):\n",
    "    res = (x - x.mean()) / x.std()\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_st = X.copy()\n",
    "X_st[:, 2] = standard_scale(X[:, 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "    res = 1 / (1 + np.exp(-z))\n",
    "    return res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. *Измените функцию calc_logloss так, чтобы нули по возможности не попадали в np.log."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.052685257853913287"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def calc_logloss(y, y_pred):\n",
    "    y_pred = y_pred.astype(np.float64)\n",
    "#     print(y_pred)\n",
    "    y_pred[y_pred==1] = 1 - 1e-5\n",
    "    y_pred[y_pred<=1e-10] = 1e-5\n",
    "#     print(y_pred)\n",
    "    err = - np.mean(y * np.log(y_pred) + (1.0 - y) * np.log(1.0 - y_pred))\n",
    "    return err\n",
    "\n",
    "# Пример применения\n",
    "y1 = np.array([1, 0])\n",
    "y_pred1 = np.array([1, 0.1])\n",
    "calc_logloss(y1, y_pred1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Подберите аргументы функции eval_model для логистической регрессии таким образом, чтобы log loss был минимальным.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Изменим функцию eval_model, чтобы промежуточные результаты добавлялись о внешний список"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1)\n",
    "def eval_model(X, y, iterations, eta=1e-4):\n",
    "    np.random.seed(42)\n",
    "    W = np.random.randn(X.shape[1])\n",
    "    n = X.shape[0]\n",
    "    \n",
    "    for i in range(iterations):\n",
    "        z = np.dot(X, W)\n",
    "        y_pred = sigmoid(z)\n",
    "        err = calc_logloss(y, y_pred)\n",
    "        \n",
    "        dQ = 1/n * X.T @ (y_pred - y)\n",
    "        W -= eta * dQ\n",
    "#         if i % (iterations / 10) == 0:\n",
    "#             print(i, W, err)\n",
    "    result_list.append([i, eta, iterations, W, err])\n",
    "    return W"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь можно пройтись вложенным циклом меняя гиперпараметры."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "eta_list = np.geomspace(1e-5, 1000, num=30)\n",
    "iter_list = np.arange(500, 500000, 5000)\n",
    "# eta_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ох и переборщил я тут с перебором :) сохраню только лучший результат\n",
    "\n",
    "result_list = [[495499,\n",
    " 6.2101694189156165,\n",
    " 495500,\n",
    " [ 5.84269302,  2.392024  , -1.9952367 ,  6.95637343],\n",
    " 1.1491483073229742e-06]]\n",
    "\n",
    "# for iteration in iter_list:\n",
    "#     for eta in eta_list:\n",
    "#         W = eval_model(X_st, y, iterations=iteration, eta=eta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[495499,\n",
       " 6.2101694189156165,\n",
       " 495500,\n",
       " [5.84269302, 2.392024, -1.9952367, 6.95637343],\n",
       " 1.1491483073229742e-06]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min_eta = 1e10\n",
    "\n",
    "for i, result in enumerate(result_list):\n",
    "    if result[4] < min_eta:\n",
    "        min_eta = result[4]\n",
    "        min_eta_params = result\n",
    "min_eta_params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Видим, что оптимальное eta находится в районе 6.2, что касается итерраций - для данной модели число получилось максимальное из заданных. Тестовых данных для проверки все равно нет, остановлюсь на этих параметрах и обучу модель."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-294.43093018,  -20.18131084,  -87.72903953,  224.18278007])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W = eval_model(X_st, y, iterations=500000, eta=6.2)\n",
    "W"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Создайте функцию calc_pred_proba, возвращающую предсказанную вероятность класса 1 (на вход подаются W, который уже посчитан функцией eval_model и X, на выходе - массив y_pred_proba).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для определения вероятности найдем сигмоид для произведения весов на признаки, последние необходимо транспонировать."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_pred_proba(W, X):\n",
    "    y_pred_proba = sigmoid(np.dot(W,X.T))\n",
    "    return y_pred_proba\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.10851882e-02, 2.16174870e-18, 1.00000000e+00, 1.36040102e-45,\n",
       "       9.99420193e-01, 1.74601372e-17, 1.00000000e+00, 1.07077081e-04,\n",
       "       9.89596506e-01, 1.00000000e+00])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calc_pred_proba(W, X_st)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Создайте функцию calc_pred, возвращающую предсказанный класс (на вход подаются W, который уже посчитан функцией eval_model и X, на выходе - массив y_pred)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "То же самое что в 3 задании, но результат сравниваем с пороговым значением, и записываем 1, если сигмоид больше, 0 если меньше. Впрочем, вывод предыдущей функции показал, что от параметра t мало что зависит..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_pred(W, X, t=0.5):\n",
    "    y_pred = sigmoid(np.dot(W,X.T)) > t\n",
    "    return y_pred.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 1, 0, 1, 0, 1, 0, 1, 1])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = calc_pred(W, X_st)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 1, 0, 1, 0, 1, 0, 1, 1])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. *Реализуйте функции для подсчета Accuracy, матрицы ошибок, точности и полноты, а также F1 score.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Модель получилась \"суперточная\", все меры равняются 1, поэтому я решил обучить ее на менее подходящих параметрах, чтобы появились ошибки, и найденные меры могли на них реагировать."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 1, 0, 1, 0, 1, 1, 1, 1])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = calc_pred(eval_model(X_st, y, 500, 6.2), X_st)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracy это доля правильных ответов ко всем ответам."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "true_y = sum(y_pred==y)\n",
    "accuracy = true_y/len(y)\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для построения матрицы ошибок, создадим список пар предсказанных / реальных значений"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "pair_y = list(zip(y_pred,y.astype(int)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Создадим возможные комбинации и циклом будем инкрементировать одну из них, сравнивая пары"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tp: 5   tn: 3 fp: 0   fn: 2\n"
     ]
    }
   ],
   "source": [
    "tp, tn, fp, fn = 0, 0, 0, 0\n",
    "\n",
    "for pred, real in pair_y:\n",
    "    if pred:\n",
    "        if real:\n",
    "            tp+= 1\n",
    "        else:\n",
    "            fn += 1\n",
    "    else:\n",
    "        if real:\n",
    "            fp += 1\n",
    "        else:\n",
    "            tn +=1\n",
    "\n",
    "print(f'tp: {tp}   tn: {tn} fp: {fp}   fn: {fn}')\n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь по определениям:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision: 1.0   recall: 0.7142857142857143\n"
     ]
    }
   ],
   "source": [
    "precision = tp / (tp + fp)\n",
    "recall = tp / (tp + fn)\n",
    "print(f'precision: {precision}   recall: {recall}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Найдем F-меру по формуле:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8333333333333333"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f_score = 2 * precision * recall / (precision + recall)\n",
    "f_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Могла ли модель переобучиться? Почему?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "На датасете из 10 наблюдений сложно говорить о переобуении) данных слишком мало даже чтобы уловить закономерность, будут другие, тестовые данные - скорее всего модель начнет безбожно врать, но в данном случае это свидетельствует о малой обучающей выборке. \n",
    "Вообще, логистическая регрессия строит гиперплоскость, рассекая пространство признаков на два подпространства. После подбора оптимальных параметров, ситуация стабилизируется и больше плоскость двигаться почти не будет. \n",
    "Другое дело, если признаков много и не все из них значащие. Пытаясь найти закономерность случайном признаке, регрессия может приспособиться на трейне, и, ориентируясь на этот шум, начать подвирать на тесте. Такая ситуация была во второй части вебинара. Поэтому, прежде чем обучать модель, стоит посмотреть значимость признаков."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Lesson_3.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
